{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.base import BaseEstimator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing(as_frame=True)\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "X_test_scaled = StandardScaler().fit_transform(X_test)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: BaseEstimator, params_grid: dict, X_train: DataFrame, y_train: DataFrame, nb_jobs: int = None) -> tuple[BaseEstimator,dict]:\n",
    "    # Define the search\n",
    "    search = GridSearchCV(model, params_grid, scoring='neg_mean_squared_error', n_jobs=nb_jobs)\n",
    "    \n",
    "    # Fit the search\n",
    "    search.fit(X_train, y_train)\n",
    "    best_estimator = search.best_estimator_\n",
    "    best_estimator.fit(X_train, y_train)\n",
    "    return best_estimator, search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute_model(model: BaseEstimator, X_test: DataFrame, y_test: DataFrame) -> dict:\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores = {\n",
    "        \"mean_squared_error\": mean_squared_error(y_test, y_pred),\n",
    "        \"mean_absolute_error\": mean_absolute_error(y_test, y_pred),\n",
    "        \"r2\": r2_score(y_test, y_pred),\n",
    "    }\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(run_name, params, metrics, tags=None)  -> None:\n",
    "    rel_path = \"mlflow.db\"\n",
    "    mlflow.set_tracking_uri(f\"sqlite:///{rel_path}\")\n",
    "    mlflow.set_experiment(\"Imo\")\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        if tags:\n",
    "            mlflow.set_tags(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evalute_log(model: BaseEstimator, params_grid: dict, X_train: DataFrame, y_train: DataFrame,\n",
    "                       X_test: DataFrame, y_test: DataFrame, run_name: str, tags: dict =None, n_jobs: int = None) -> None:\n",
    "    best_estimator, best_params = train_model(model, params_grid, X_train, y_train, n_jobs)\n",
    "    metrics = evalute_model(best_estimator, X_test, y_test)\n",
    "    log_metrics(run_name, best_params, metrics, tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/15 19:38:17 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/01/15 19:38:17 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025/01/15 19:38:18 INFO mlflow.tracking.fluent: Experiment with name 'Imo' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "scores = evalute_model(lr, X_test, y_test)\n",
    "log_metrics(\"LinearRegression\", {}, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "scores = evalute_model(lr, X_test_scaled, y_test)\n",
    "log_metrics(\"LinearRegression_scaled\", {}, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séléction de variable pour le modèle linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_seq_backwark = SequentialFeatureSelector(\n",
    "    estimator=LinearRegression(), direction=\"backward\", n_features_to_select=\"auto\", cv=3,\n",
    ")\n",
    "mod_seq_forward = SequentialFeatureSelector(\n",
    "    estimator=LinearRegression(), direction=\"forward\", n_features_to_select=\"auto\", cv=3\n",
    ")\n",
    "mod_seqs = { 'backward': mod_seq_backwark, \n",
    "'forward': mod_seq_forward\n",
    "}\n",
    "for mode, mod_seq in mod_seqs.items():\n",
    "    X_train_seq = mod_seq.fit_transform(X_train, y_train)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_seq, y_train)\n",
    "    X_test_seq = mod_seq.transform(X_test)\n",
    "    scores = evalute_model(model, X_test_seq, y_test)\n",
    "    log_metrics(f\"LinearRegression_{mode}\", {}, scores, {\"features\": X.columns[mod_seq.get_support()].to_list()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_seq_backwark = SequentialFeatureSelector(\n",
    "    estimator=LinearRegression(), direction=\"backward\", n_features_to_select=\"auto\", cv=3,\n",
    ")\n",
    "mod_seq_forward = SequentialFeatureSelector(\n",
    "    estimator=LinearRegression(), direction=\"forward\", n_features_to_select=\"auto\", cv=3,\n",
    ")\n",
    "mod_seqs = { 'backward': mod_seq_backwark, \n",
    "'forward': mod_seq_forward\n",
    "}\n",
    "for mode, mod_seq in mod_seqs.items():\n",
    "    X_train_seq = mod_seq.fit_transform(X_train_scaled, y_train)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_seq, y_train)\n",
    "    X_test_seq = mod_seq.transform(X_test_scaled)\n",
    "    scores = evalute_model(model, X_test_seq, y_test)\n",
    "    log_metrics(f\"LinearRegression_scaled_{mode}\", {}, scores, {\"features\": X.columns[mod_seq.get_support()].to_list()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = { \"alpha\": np.logspace(-3, 3, 50) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evalute_log(Ridge(random_state=random_state), params_grid, X_train, y_train, X_test, y_test, \"Ridge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evalute_log(Ridge(random_state=random_state), params_grid, X_train_scaled, y_train, X_test_scaled, y_test, \"Ridge_scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evalute_log(Lasso(random_state=random_state), params_grid, X_train, y_train, X_test, y_test, \"Lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evalute_log(Lasso(random_state=random_state), params_grid, X_train_scaled, y_train, X_test_scaled, y_test, \"Lasso_scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = { \"alpha\": np.logspace(-3, 3, 50), \"l1_ratio\": np.linspace(0.001, 0.999, 50) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evalute_log(ElasticNet(random_state=random_state), params_grid, X_train, y_train, X_test, y_test, \"ElasticNet\", n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evalute_log(ElasticNet(random_state=random_state), params_grid, X_train_scaled, y_train, X_test_scaled, y_test, \"ElasticNet_scaled\", n_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = { \"max_depth\": [None, 3, 5, 7, 9, 11, 13, 15] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evalute_log(DecisionTreeRegressor(random_state=random_state), params_grid, X_train, y_train, X_test, y_test, \"DecisionTree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evalute_log(DecisionTreeRegressor(random_state=random_state), params_grid, X_train_scaled, y_train, X_test_scaled, y_test, \"DecisionTree_scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = { \"max_depth\": [None, 3, 4, 5],\n",
    "                \"n_estimators\": [75, 100, 150] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evalute_log(RandomForestRegressor(random_state=random_state), params_grid, X_train, y_train, X_test, y_test, \"RandomForest\", n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = { \"max_depth\": [None, 3, 4, 5],\n",
    "                \"n_estimators\": [75, 100, 150],\n",
    "                 \"learning_rate\": [0.05, 0.1, 0.15] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evalute_log(GradientBoostingRegressor(random_state=random_state), params_grid, X_train, y_train, X_test, y_test, \"GradientBoosting\", n_jobs=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
